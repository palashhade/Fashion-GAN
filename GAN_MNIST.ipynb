{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eQeMgYYSqaS"
      },
      "source": [
        "This project is done on the MNIST TF dataset which consists of a GAN model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7T_j7mv5SzG-"
      },
      "source": [
        "### **1. Import Dependencies and Data**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MvnTyKZrSqGA"
      },
      "outputs": [],
      "source": [
        "#Setting up environment.\n",
        "#Installing Dependencies\n",
        "# Om Sai Ram\n",
        "\n",
        "!pip install matplotlib tensorflow-datasets ipywidgets\n",
        "\n",
        "#(This command is needed when project is implmented locally or on jupyter notebook.)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6mC4ljJSjxw"
      },
      "outputs": [],
      "source": [
        "!pip list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tjXJVJZ5WJ1D"
      },
      "outputs": [],
      "source": [
        "#To limit memory growth in case you are running it locally\n",
        "import tensorflow as tf\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "for gpu in gpus:\n",
        "  tf.config.experimental.set_memory_growth(gpu, True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wege_4-EWoe8"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "tf.config.experimental.list_physical_devices(\"GPU\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afbakTavXEdb"
      },
      "outputs": [],
      "source": [
        "#Bringing in rest of the dependencies\n",
        "import tensorflow_datasets as tfds\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BHXL6IcaYuTI"
      },
      "outputs": [],
      "source": [
        "#Downloading and importing the dataset and loading it .\n",
        "\n",
        "\n",
        "\n",
        "ds = tfds.load(\"fashion_mnist\",split = \"train\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1BHYfhs_ZgUI"
      },
      "outputs": [],
      "source": [
        "ds.as_numpy_iterator().next()['image']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYhMqKsXZ5kR"
      },
      "source": [
        "### **Visualize images and build data pipeline**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1y-tlASZ4Oq"
      },
      "outputs": [],
      "source": [
        "#Visualizing data.\n",
        "#Do some data transformation.\n",
        "import numpy as np\n",
        "#building an as_numpy_iterator\n",
        "#OmSaiRam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Lvz5uNBayeI"
      },
      "outputs": [],
      "source": [
        "#Setup Connection aka iterator\n",
        "dataiterator = ds.as_numpy_iterator()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ixb0Gd6PayQr"
      },
      "outputs": [],
      "source": [
        "# Getting data out of the pipeline.\n",
        "dataiterator.next()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AvNCf1bEosN8"
      },
      "outputs": [],
      "source": [
        "#Creating subplots\n",
        "\n",
        "fig, ax = plt.subplots(ncols = 4, figsize = (20,20))\n",
        "#Loop Four times and get images.\n",
        "for idx in range(4):\n",
        "  sample = dataiterator.next()\n",
        "  #squeeze just reduces it from 3 dimensional (28,28,1) to (28,28)\n",
        "  ax[idx].imshow(np.squeeze(sample['image']))\n",
        "  ax[idx].title.set_text(sample['label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fm4egvtMo8qp"
      },
      "outputs": [],
      "source": [
        "# scale values between 0 and 1 that are currently between 0 and 255\n",
        "def scale_images(data):\n",
        "  image = data['image']\n",
        "  return image/255"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sV2dZEBdpxhT"
      },
      "source": [
        "We have to map, cache, shuffle, batch, prefetch.\n",
        "\n",
        "Steps for building a data pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tVa8xeAjspUO"
      },
      "outputs": [],
      "source": [
        "#Reloaded the dataset.\n",
        "ds = tfds.load('fashion_mnist',split = 'train')\n",
        "#Running the dataset through the scale_images preprocessing step\n",
        "ds = ds.map(scale_images)\n",
        "#Cache dataset for batch\n",
        "ds = ds.cache()\n",
        "#Shuffle it up\n",
        "ds = ds.shuffle(60000)\n",
        "#Batch into 128 images per sample\n",
        "ds = ds.batch(128)\n",
        "#Reduce the likelihood of bottlenecking.\n",
        "ds = ds.prefetch(64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0qs7IDNkt1P2"
      },
      "outputs": [],
      "source": [
        "ds.as_numpy_iterator().next().shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UKMFP70vEss"
      },
      "source": [
        "###**Building the Neural Network.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFb2t8nPvUnq"
      },
      "source": [
        "####**Importing Modelling Components.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wVYx-JwlvYcZ"
      },
      "outputs": [],
      "source": [
        "#Importing the dependencies\n",
        "from tensorflow.keras.models import Sequential\n",
        "#Bringing in the layers for the neural network.\n",
        "from tensorflow.keras.layers import Conv2D, Dense, Reshape, Flatten, LeakyReLU, Dropout, UpSampling2D\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SalJGhxazeLj"
      },
      "source": [
        "####**Building a Generator**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NKaHG7ZvzIlK"
      },
      "outputs": [],
      "source": [
        "def build_generator():\n",
        "  model = Sequential()\n",
        "\n",
        "  #Takes in random values to 7*7*128 - beginnings\n",
        "  # of a generated image.\n",
        "  model.add(Dense(7*7*128, input_dim = 128))\n",
        "  model.add(LeakyReLU(0.2))\n",
        "  model.add(Reshape((7,7,128)))\n",
        "\n",
        "  #Upsampling block 1\n",
        "  model.add(UpSampling2D())\n",
        "  model.add(Conv2D(128,5,padding = 'same'))\n",
        "  model.add(LeakyReLU(0.2))\n",
        "\n",
        "  #Upsampling block 2\n",
        "  model.add(UpSampling2D())\n",
        "  model.add(Conv2D(128,5,padding = 'same'))\n",
        "  model.add(LeakyReLU(0.2))\n",
        "\n",
        "  # convolutional block\n",
        "  model.add(Conv2D(128,4, padding = 'same'))\n",
        "  model.add(LeakyReLU(0.2))\n",
        "\n",
        "  #Convolutional block\n",
        "  model.add(Conv2D(128,4, padding = 'same'))\n",
        "  model.add(LeakyReLU(0.2))\n",
        "\n",
        "  # Conv layer to get to one channel\n",
        "  model.add(Conv2D(1,4,padding = 'same',activation = 'sigmoid'))\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQ-b2q934gIB"
      },
      "outputs": [],
      "source": [
        "generator = build_generator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DjuHSFVT4mE2"
      },
      "outputs": [],
      "source": [
        "generator.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u4UWVRQBYbpp"
      },
      "outputs": [],
      "source": [
        "#Testing generator\n",
        "img = generator.predict(np.random.randn(4,128,1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q3XwlYxBZMtC"
      },
      "outputs": [],
      "source": [
        "img.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6V-zjs9Y8-x"
      },
      "outputs": [],
      "source": [
        "# #Creating subplots\n",
        "# #Setting up the subplot format.\n",
        "# # fig is whole and ax is subplt\n",
        "# fig, ax = plt.subplots(ncols = 4, figsize = (20,20))\n",
        "# #Loop Four times and get images.\n",
        "# for idx, img in enumerate(img):\n",
        "#   #squeeze just reduces it from 3 dimensional (28,28,1) to (28,28)\n",
        "#   ax[idx].imshow(np.squeeze(img))\n",
        "#   ax[idx].title.set_text(idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-dfk3yOiw8h"
      },
      "outputs": [],
      "source": [
        "img.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ebyx4bHkaef4"
      },
      "source": [
        "Generator part is done here.\n",
        "\n",
        "---\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sItdKLMvajBw"
      },
      "source": [
        "####**Building Discriminator**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hvvzl1xcZmcu"
      },
      "outputs": [],
      "source": [
        "def build_discriminator():\n",
        "  model = Sequential()\n",
        "\n",
        "  #First Conv Block\n",
        "  model.add(Conv2D(32,5,input_shape =(28,28,1)))\n",
        "  model.add(LeakyReLU(0.2))\n",
        "  model.add(Dropout(0.4))\n",
        "\n",
        "  #Second Conv Block\n",
        "  model.add(Conv2D(64,5))\n",
        "  model.add(LeakyReLU(0.2))\n",
        "  model.add(Dropout(0.4))\n",
        "\n",
        "  #third Conv Block\n",
        "  model.add(Conv2D(128,5))\n",
        "  model.add(LeakyReLU(0.2))\n",
        "  model.add(Dropout(0.4))\n",
        "\n",
        "  #Fourth Conv Block\n",
        "  model.add(Conv2D(256,5))\n",
        "  model.add(LeakyReLU(0.2))\n",
        "  model.add(Dropout(0.4))\n",
        "\n",
        "  #Flatten then pass to dense layer\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dropout(0.4))\n",
        "  # 1 represents false image and 0 true image\n",
        "  model.add(Dense(1,activation = 'sigmoid'))\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9rC4xcO9a9HQ"
      },
      "outputs": [],
      "source": [
        "discriminator = build_discriminator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xtrIOXBybnks"
      },
      "outputs": [],
      "source": [
        "discriminator.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2fCrjQTwiP5b"
      },
      "outputs": [],
      "source": [
        "img.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vq3voqsIhC2r"
      },
      "outputs": [],
      "source": [
        "discriminator.predict(img)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnCRRehKk91x"
      },
      "source": [
        " img = img[0]\n",
        " As neural network expects batch if we need to pass\n",
        " image we need to do following\n",
        " discriminator.predict(np.expand_dims(img,0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHHgAvEjoTT2"
      },
      "source": [
        "####**Custom Training Loops**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXiEeDlSoZB6"
      },
      "source": [
        "#####Setup Losses and Optimizers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QfosGmNFoXY4"
      },
      "outputs": [],
      "source": [
        "# Binary Cross Entropy\n",
        "# Adam is going to be optimizer for both\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "# Binary Cross Entropy is going to be loss for both.\n",
        "from tensorflow.keras.losses import BinaryCrossentropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rjmF7rQcq8LZ"
      },
      "outputs": [],
      "source": [
        "#instances\n",
        "#learning rate\n",
        "g_opt = Adam(learning_rate = 0.0001)\n",
        "d_opt = Adam(learning_rate = 0.00001)\n",
        "\n",
        "\n",
        "#losses\n",
        "g_loss = BinaryCrossentropy()\n",
        "d_loss = BinaryCrossentropy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slRa8AjCqHF6"
      },
      "source": [
        "#####Build Subclass Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjxVD1JNnhkG"
      },
      "outputs": [],
      "source": [
        "#import model class from keras\n",
        "#Importing the base model class to subclass our trianing step\n",
        "from tensorflow.keras.models import Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Va7i788brebv"
      },
      "outputs": [],
      "source": [
        "class FashionGAN(Model):\n",
        "  def __init__(self, generator, discriminator, *args, **kwargs):\n",
        "    # Pass through args and kwargs to base class\n",
        "    super().__init__(*args,**kwargs)\n",
        "\n",
        "    #Create attributes for gen and discriminator\n",
        "    self.generator = generator\n",
        "    self.discriminator = discriminator\n",
        "\n",
        "\n",
        "  def compile(self, g_opt, d_opt, g_loss, d_loss, *args, **kwargs):\n",
        "    #Compile with base class\n",
        "    super().compile(*args,**kwargs)\n",
        "    #Create attributes for loss and optimizers\n",
        "    self.g_opt = g_opt\n",
        "    self.d_opt = d_opt\n",
        "    self.g_loss = g_loss\n",
        "    self.d_loss = d_loss\n",
        "\n",
        "  def train_step(self, batch):\n",
        "    #get the data\n",
        "    real_images = batch\n",
        "    fake_images = self.generator(tf.random.normal((128,128,1)), training = False)\n",
        "\n",
        "    #Train the discriminator\n",
        "    with tf.GradientTape() as d_tape:\n",
        "      #Pass the real and fake images to the discriminator model.\n",
        "      yhat_real = self.discriminator(real_images,training = True)\n",
        "      yhat_fake = self.discriminator(fake_images,training = True)\n",
        "\n",
        "      yhat_realfake = tf.concat([yhat_real, yhat_fake], axis = 0)\n",
        "\n",
        "\n",
        "      #Create labels for real and fake images.\n",
        "      y_realfake = tf.concat([tf.zeros_like(yhat_real),tf.ones_like(yhat_fake)], axis = 0)\n",
        "\n",
        "      #Add some noise to the outputs\n",
        "      noise_real = 0.15* tf.random.uniform(tf.shape(yhat_real))\n",
        "      noise_fake = -0.15* tf.random.uniform(tf.shape(yhat_fake))\n",
        "      y_realfake += tf.concat([noise_real, noise_fake],axis = 0)\n",
        "\n",
        "      #Calculate loss - BINARYCROSS\n",
        "      total_d_loss = self.d_loss(y_realfake, yhat_realfake)\n",
        "\n",
        "\n",
        "    #Apply Backpropogation -- nn learn\n",
        "    dgrad = d_tape.gradient(total_d_loss, self.discriminator.trainable_variables)\n",
        "\n",
        "    self.d_opt.apply_gradients(zip(dgrad, self.discriminator.trainable_variables))\n",
        "\n",
        "    #Train the generator.\n",
        "    with tf.GradientTape() as g_tape:\n",
        "      #Generate some new images\n",
        "      gen_images = self.generator(tf.random.normal((128,128,1)), training = True)\n",
        "\n",
        "      #Create the predicted labels\n",
        "      predicted_labels = self.discriminator(gen_images, training = False)\n",
        "\n",
        "      # Calculate loss - trick to training to fake out the discriminator\n",
        "      total_g_loss = self.g_loss(tf.zeros_like(predicted_labels), predicted_labels)\n",
        "\n",
        "\n",
        "    # Apply backprop\n",
        "    ggrad = g_tape.gradient(total_g_loss, self.generator.trainable_variables)\n",
        "\n",
        "    self.g_opt.apply_gradients(zip(ggrad, self.generator.trainable_variables))\n",
        "\n",
        "\n",
        "    return{\"d_loss\":total_d_loss, \"g_loss\":total_g_loss}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "awOj9qTIrtyP"
      },
      "outputs": [],
      "source": [
        "#Creating instance of the subclass model\n",
        "fashgan = FashionGAN(generator, discriminator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBFMMGFRel6t"
      },
      "outputs": [],
      "source": [
        "# Compile the model.\n",
        "fashgan.compile(g_opt, d_opt, g_loss, d_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Cylz-vde1K3"
      },
      "source": [
        "#####**Build Callback**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VkDhfFEaeuf0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from tensorflow.keras.preprocessing.image import array_to_img\n",
        "from tensorflow.keras.callbacks import Callback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lag4n_w_2TVY"
      },
      "outputs": [],
      "source": [
        "class ModelMonitor(Callback):\n",
        "  def __init__(self, num_img = 3, latent_dim = 128):\n",
        "    self.num_img = num_img\n",
        "    self.latent_dim = latent_dim\n",
        "\n",
        "  def on_epoch_end(self,epoch, logs = None):\n",
        "    random_latent_vectors = tf.random.uniform((self.num_img, self.latent_dim, 1))\n",
        "    generated_images = self.model.generator(random_latent_vectors)\n",
        "    generated_images*=255\n",
        "    generated_images.numpy()\n",
        "    for i in range(self.num_img):\n",
        "      img = array_to_img(generated_images[i])\n",
        "      img.save(os.path.join('images',f'generated_img_{epoch}_{i}.png'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FM7ooK1V83dE"
      },
      "source": [
        "#####**Train**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GEoKxZUZ9Alm"
      },
      "outputs": [],
      "source": [
        "ds.as_numpy_iterator().next()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0hNQlhbq85lT"
      },
      "outputs": [],
      "source": [
        "#Recommend 2000 epochs\n",
        "hist = fashgan.fit(ds, epochs = 2, callbacks = [ModelMonitor()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dj6EMdKvJXCE"
      },
      "source": [
        "#####**Review Performance**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mywvKh8_JjVI"
      },
      "outputs": [],
      "source": [
        "plt.suptitle(\"Loss\")\n",
        "plt.plot(hist.history['d_loss'], label = 'd_loss')\n",
        "plt.plot(hist.history['g_loss'], label = 'g_loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x53Uz--RKaPz"
      },
      "source": [
        "####**Test Out the Generator**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjUOzpDgKeZ8"
      },
      "source": [
        "#####**Generate Images**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z1rdPvMJLygq"
      },
      "outputs": [],
      "source": [
        "\n",
        "#loading the weights\n",
        "# In case you want to take the pretrained model\n",
        "generator.load_weights(os.path.join('', 'generatormodel.h5'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZPQpjpVrKleI"
      },
      "outputs": [],
      "source": [
        "imgs = generator.predict(tf.random.normal((16,128,1)))\n",
        "imgs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2NY7hYCuLI05"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(ncols = 8, nrows = 8, figsize = (20,20))\n",
        "for r in range(8):\n",
        "  for c in range(8):\n",
        "    ax[r][c].imshow(imgs[(r+1)*(c+1)-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIyl1sUQKg8V"
      },
      "source": [
        "#####**Save the Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SXAyTxaxJ3Yq"
      },
      "outputs": [],
      "source": [
        "generator.save('generator.h5')\n",
        "discriminator.save('discriminator.h5')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
